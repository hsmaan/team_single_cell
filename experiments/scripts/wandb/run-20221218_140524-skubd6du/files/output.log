
Reading dataset...
Feature selecting GEX...
 UserWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:64: `flavor='seurat_v3'` expects raw count data, but non-integers were found.
Trying to set attribute `._uns` of view, copying.
Feature selecting ATAC...
Trying to set attribute `.var` of view, copying.
New GEX dim: 2500;
New ATAC dim: 10002;
AnnData dataset's shape: (69249, 12502)
Initializing dataset and dataloader...
The order of labels: ['s1d1', 's1d1', 's1d1', 's1d1', 's1d1', ..., 's4d9', 's4d9', 's4d9', 's4d9', 's4d9']
Length: 69249
Categories (13, object): ['s1d1', 's1d2', 's1d3', 's2d1', ..., 's3d10', 's4d1', 's4d8', 's4d9']
The device: cuda;
The model: DeepGexAtacMultiModalAutoencoder(
  (gex_encoder): Sequential(
    (0): Linear(in_features=2500, out_features=1200, bias=True)
    (1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1200, out_features=400, bias=True)
    (5): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=400, out_features=100, bias=True)
    (8): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=100, out_features=64, bias=True)
    (12): ReLU()
  )
  (atac_encoder): Sequential(
    (0): Linear(in_features=10002, out_features=1600, bias=True)
    (1): BatchNorm1d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1600, out_features=600, bias=True)
    (5): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=600, out_features=120, bias=True)
    (8): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=120, out_features=64, bias=True)
    (12): ReLU()
  )
  (gex_decoder): Sequential(
    (0): Linear(in_features=128, out_features=50, bias=True)
    (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=50, out_features=100, bias=True)
    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=100, out_features=200, bias=True)
    (8): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=200, out_features=2500, bias=True)
    (12): ReLU()
  )
  (atac_decoder): Sequential(
    (0): Linear(in_features=128, out_features=60, bias=True)
    (1): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=60, out_features=100, bias=True)
    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=100, out_features=150, bias=True)
    (8): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=150, out_features=10002, bias=True)
    (12): Sigmoid()
  )
);
The dataset: <datasets.anndatadataset.AnnDataDataset object at 0x7f2781c55590>;
The optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.03552316626319454
);
Epoch 0 recon loss: 9126.4829736062
Epoch 1 recon loss: 9399.7048281576
Epoch 2 recon loss: 8820.3900160799
Epoch 3 recon loss: 8792.6110316868
Epoch 4 recon loss: 8661.5780009408
Epoch 5 recon loss: 8412.7339004859
Epoch 6 recon loss: 8042.6544618024
Epoch 7 recon loss: 8090.594166463
Epoch 8 recon loss: 7350.6932420292
Epoch 9 recon loss: 7310.4394947744
Epoch 10 recon loss: 7235.9913292065
Epoch 11 recon loss: 6663.4275538645
Epoch 12 recon loss: 6680.8796279979
Epoch 13 recon loss: 6276.9973035664
Epoch 14 recon loss: 6158.6123356959
Epoch 15 recon loss: 5895.035911141
Epoch 16 recon loss: 5582.6653824352
Epoch 17 recon loss: 5519.3849803425
Epoch 18 recon loss: 5212.5452448907
Epoch 19 recon loss: 4972.7742567124
Epoch 20 recon loss: 4775.8153717017
Epoch 21 recon loss: 4551.8482558742
Epoch 22 recon loss: 4336.5738719261
Epoch 23 recon loss: 4060.9057889493
Epoch 24 recon loss: 3890.9879571083
Epoch 25 recon loss: 3987.7313090662
Epoch 26 recon loss: 3557.9432567931
Epoch 27 recon loss: 3307.2681302086
Epoch 28 recon loss: 3245.8212741206
Epoch 29 recon loss: 3308.5236440911
Epoch 30 recon loss: 3027.955073081
Epoch 31 recon loss: 2831.5309233668
Epoch 32 recon loss: 2805.2497072213
Epoch 33 recon loss: 2491.8849319445
Epoch 34 recon loss: 2543.8178076303
Epoch 35 recon loss: 2159.2935711877
Epoch 36 recon loss: 2169.64007468
Epoch 37 recon loss: 2170.8260243139
Epoch 38 recon loss: 2115.8469775666
Epoch 39 recon loss: 2007.8254608268
