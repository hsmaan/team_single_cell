
Reading dataset...
Feature selecting GEX...
 UserWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:64: `flavor='seurat_v3'` expects raw count data, but non-integers were found.
Trying to set attribute `._uns` of view, copying.
Feature selecting ATAC...
Trying to set attribute `.var` of view, copying.
New GEX dim: 1000;
New ATAC dim: 10002;
AnnData dataset's shape: (69249, 11002)
Initializing dataset and dataloader...
The order of labels: ['s1d1', 's1d1', 's1d1', 's1d1', 's1d1', ..., 's4d9', 's4d9', 's4d9', 's4d9', 's4d9']
Length: 69249
Categories (13, object): ['s1d1', 's1d2', 's1d3', 's2d1', ..., 's3d10', 's4d1', 's4d8', 's4d9']
The device: cuda;
The model: DeepGexAtacMultiModalAutoencoder(
  (gex_encoder): Sequential(
    (0): Linear(in_features=1000, out_features=1600, bias=True)
    (1): BatchNorm1d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1600, out_features=800, bias=True)
    (5): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=800, out_features=400, bias=True)
    (8): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=400, out_features=100, bias=True)
    (12): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Linear(in_features=100, out_features=64, bias=True)
    (15): ReLU()
  )
  (atac_encoder): Sequential(
    (0): Linear(in_features=10002, out_features=2400, bias=True)
    (1): BatchNorm1d(2400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=2400, out_features=1200, bias=True)
    (5): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=1200, out_features=400, bias=True)
    (8): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=400, out_features=100, bias=True)
    (12): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Linear(in_features=100, out_features=64, bias=True)
    (15): ReLU()
  )
  (gex_decoder): Sequential(
    (0): Linear(in_features=128, out_features=200, bias=True)
    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=200, out_features=400, bias=True)
    (5): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=400, out_features=900, bias=True)
    (8): BatchNorm1d(900, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=900, out_features=2000, bias=True)
    (12): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Linear(in_features=2000, out_features=1000, bias=True)
    (15): ReLU()
  )
  (atac_decoder): Sequential(
    (0): Linear(in_features=128, out_features=160, bias=True)
    (1): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=160, out_features=500, bias=True)
    (5): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=500, out_features=1500, bias=True)
    (8): BatchNorm1d(1500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=1500, out_features=2400, bias=True)
    (12): BatchNorm1d(2400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Linear(in_features=2400, out_features=10002, bias=True)
    (15): Sigmoid()
  )
);
The dataset: <datasets.anndatadataset.AnnDataDataset object at 0x7f7f9a887210>;
The optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.04030687350142595
);
Epoch 0 recon loss: 32439.8379342965
Epoch 1 recon loss: 30724.2293097225
Epoch 2 recon loss: 31273.3714631919
Epoch 3 recon loss: 30219.9303012154
Epoch 4 recon loss: 29501.3026266465
Epoch 5 recon loss: 28700.8609154186
Epoch 6 recon loss: 28475.8204082281
Epoch 7 recon loss: 27457.5684456119
Epoch 8 recon loss: 26776.6215063365
Epoch 9 recon loss: 25076.5717965509
Epoch 10 recon loss: 24183.4631601623
Epoch 11 recon loss: 24466.2987902897
Epoch 12 recon loss: 23784.8058462783
Epoch 13 recon loss: 22807.9419745542
Epoch 14 recon loss: 22152.3505584904
Epoch 15 recon loss: 21831.7577973824
Epoch 16 recon loss: 21181.0471786076
Epoch 17 recon loss: 20073.4868993585
Epoch 18 recon loss: 19640.5998617525
Epoch 19 recon loss: 19471.212073502
Epoch 20 recon loss: 18463.7819082305
Epoch 21 recon loss: 18270.7266825554
Epoch 22 recon loss: 17788.8744230264
Epoch 23 recon loss: 16983.3384872912
Epoch 24 recon loss: 16152.1860324021
Epoch 25 recon loss: 15915.054340112
Epoch 26 recon loss: 15510.5760631473
Epoch 27 recon loss: 14685.1151111751
Epoch 28 recon loss: 14353.3824291975
Epoch 29 recon loss: 13894.9905155422
Epoch 30 recon loss: 13174.2659241512
Epoch 31 recon loss: 12760.5868384976
Epoch 32 recon loss: 12074.8523840648
Epoch 33 recon loss: 12358.2278520724
Epoch 34 recon loss: 11977.0056689295
Epoch 35 recon loss: 11064.7174957494
Epoch 36 recon loss: 11108.5263053191
Epoch 37 recon loss: 10223.4634583884
Epoch 38 recon loss: 10460.5387387705
Epoch 39 recon loss: 9743.9950192792
Epoch 40 recon loss: 9579.9980596813
Epoch 41 recon loss: 9095.717473422
Epoch 42 recon loss: 8809.3996958019
Epoch 43 recon loss: 8515.937474138
Epoch 44 recon loss: 8240.1302105324
Epoch 45 recon loss: 7895.036267672
Epoch 46 recon loss: 7837.4923184591
Epoch 47 recon loss: 7509.3639535358
Epoch 48 recon loss: 7178.2564277995
Epoch 49 recon loss: 6297.7127477547
Epoch 50 recon loss: 6556.1259688206
Epoch 51 recon loss: 6458.4365399033
Epoch 52 recon loss: 6035.6106164039
Epoch 53 recon loss: 5657.6891944129
Epoch 54 recon loss: 5467.2376519028
Epoch 55 recon loss: 5291.7332981448
Epoch 56 recon loss: 5331.731479795
Epoch 57 recon loss: 4791.1795146927
Epoch 58 recon loss: 4674.5652420565
Epoch 59 recon loss: 4878.4155854342
Epoch 60 recon loss: 4341.5235344866
Epoch 61 recon loss: 4415.9601154359
Epoch 62 recon loss: 4487.7156424905
Epoch 63 recon loss: 3776.4155050485
Epoch 64 recon loss: 3734.8563546485
Epoch 65 recon loss: 3660.4940089223
Epoch 66 recon loss: 3380.7469085353
Epoch 67 recon loss: 3437.0330383551
Epoch 68 recon loss: 3009.2074414826
Epoch 69 recon loss: 2990.0246810551
Epoch 70 recon loss: 2957.2582987478
Epoch 71 recon loss: 3087.0569893575
Epoch 72 recon loss: 2808.1095097087
Epoch 73 recon loss: 2634.6373083333
Epoch 74 recon loss: 2400.516823766
Epoch 75 recon loss: 2616.8717327915
Epoch 76 recon loss: 2282.9610822811
Epoch 77 recon loss: 2194.9986156918
Epoch 78 recon loss: 2433.135947746
Epoch 79 recon loss: 2092.7614156933
Epoch 80 recon loss: 2195.059203668
Epoch 81 recon loss: 1528.8370890013
Epoch 82 recon loss: 2027.7639073388
Epoch 83 recon loss: 2206.1283673055
Epoch 84 recon loss: 1721.6615896042
Epoch 85 recon loss: 1552.9758875143
Epoch 86 recon loss: 1838.4564473073
Epoch 87 recon loss: 2070.0877412776
Epoch 88 recon loss: 1485.315861189
Epoch 89 recon loss: 1658.1249126577
Epoch 90 recon loss: 1444.0137587851
Epoch 91 recon loss: 1331.1448852706
Epoch 92 recon loss: 1634.8103045054
Epoch 93 recon loss: 1560.7647161666
Epoch 94 recon loss: 1309.0858002295
Epoch 95 recon loss: 1244.0760682409
Epoch 96 recon loss: 1386.7120860075
Epoch 97 recon loss: 1930.4884797847
Epoch 98 recon loss: 1415.5854177933
Epoch 99 recon loss: 1297.527259255
Latent space type: <class 'numpy.ndarray'>;
GEX encoded shape: torch.Size([69249, 64]);
ATAC encoded shape: torch.Size([69249, 64]);
Latent space shape: (69249, 128);
0.578890797154631
   celltype_ari  celltype_ami  ...  batch_homogeneity  batch_complete
0      0.177547      0.441904  ...           0.830393        0.875314
[1 rows x 8 columns]
 FutureWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/anndata/_core/anndata.py:1228: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.
... storing 'feature_types' as categorical
 FutureWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/anndata/_core/anndata.py:1228: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.
... storing 'gene_id' as categorical