
Reading dataset...
Feature selecting GEX...
 UserWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:64: `flavor='seurat_v3'` expects raw count data, but non-integers were found.
Trying to set attribute `._uns` of view, copying.
Feature selecting ATAC...
Trying to set attribute `.var` of view, copying.
New GEX dim: 1000;
New ATAC dim: 5001;
AnnData dataset's shape: (69249, 6001)
Initializing dataset and dataloader...
The order of labels: ['s1d1', 's1d1', 's1d1', 's1d1', 's1d1', ..., 's4d9', 's4d9', 's4d9', 's4d9', 's4d9']
Length: 69249
Categories (13, object): ['s1d1', 's1d2', 's1d3', 's2d1', ..., 's3d10', 's4d1', 's4d8', 's4d9']
The device: cuda;
The model: DeepGexAtacMultiModalAutoencoder(
  (gex_encoder): Sequential(
    (0): Linear(in_features=1000, out_features=1200, bias=True)
    (1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1200, out_features=400, bias=True)
    (5): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=400, out_features=100, bias=True)
    (8): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=100, out_features=10, bias=True)
    (12): ReLU()
  )
  (atac_encoder): Sequential(
    (0): Linear(in_features=5001, out_features=1600, bias=True)
    (1): BatchNorm1d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1600, out_features=600, bias=True)
    (5): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=600, out_features=120, bias=True)
    (8): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=120, out_features=10, bias=True)
    (12): ReLU()
  )
  (gex_decoder): Sequential(
    (0): Linear(in_features=20, out_features=50, bias=True)
    (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=50, out_features=100, bias=True)
    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=100, out_features=200, bias=True)
    (8): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=200, out_features=1000, bias=True)
    (12): ReLU()
  )
  (atac_decoder): Sequential(
    (0): Linear(in_features=20, out_features=60, bias=True)
    (1): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=60, out_features=100, bias=True)
    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=100, out_features=150, bias=True)
    (8): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=150, out_features=5001, bias=True)
    (12): Sigmoid()
  )
);
The dataset: <datasets.anndatadataset.AnnDataDataset object at 0x7f6908057750>;
The optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.028194942752527465
);
Epoch 0 recon loss: 29561.2112311189
Epoch 1 recon loss: 29666.096239584
Epoch 2 recon loss: 30051.3482011333
Epoch 3 recon loss: 30201.3337343331
Epoch 4 recon loss: 29383.4572882771
Epoch 5 recon loss: 29547.9076274025
Epoch 6 recon loss: 29319.5740657457
Epoch 7 recon loss: 28507.6501702526
Epoch 8 recon loss: 29461.7772376818
Epoch 9 recon loss: 29018.858966456
Epoch 10 recon loss: 28738.0662067319
Epoch 11 recon loss: 26641.3328616276
Epoch 12 recon loss: 29140.8937478083
Epoch 13 recon loss: 29471.4328142284
Epoch 14 recon loss: 29472.0250018282
Epoch 15 recon loss: 28564.3645076694
Epoch 16 recon loss: 29538.6696839
Epoch 17 recon loss: 27916.8517711064
Epoch 18 recon loss: 28700.0740292377
Epoch 19 recon loss: 28288.0133947838
Epoch 20 recon loss: 28761.4587724429
Epoch 21 recon loss: 28685.2803725945
Epoch 22 recon loss: 28016.1344866064
Epoch 23 recon loss: 28589.0585783831
Epoch 24 recon loss: 28413.6038315416
Epoch 25 recon loss: 28410.8631800001
Epoch 26 recon loss: 28050.7190827905
Epoch 27 recon loss: 27653.7573177896
Epoch 28 recon loss: 27753.7797673563
Epoch 29 recon loss: 27782.2799272968
Epoch 30 recon loss: 26982.1435915772
Epoch 31 recon loss: 27358.7296185661
Epoch 32 recon loss: 27431.5010618437
Epoch 33 recon loss: 27382.7967283687
Epoch 34 recon loss: 27403.8718125017
Epoch 35 recon loss: 27103.0778258396
Epoch 36 recon loss: 27570.2102053371
Epoch 37 recon loss: 27207.5363238056
Epoch 38 recon loss: 26991.3557344975
Epoch 39 recon loss: 26488.7106924364
Epoch 40 recon loss: 27443.2357584669
Epoch 41 recon loss: 26616.0057956495
Epoch 42 recon loss: 26561.6828797657
Epoch 43 recon loss: 26763.2587935459
Epoch 44 recon loss: 27392.6400685445
Epoch 45 recon loss: 26141.2396826765
Epoch 46 recon loss: 25685.3324162536
Epoch 47 recon loss: 26955.3769554656
Epoch 48 recon loss: 26577.4294293251
Epoch 49 recon loss: 25839.6332673581
Epoch 50 recon loss: 25060.4218991852
Epoch 51 recon loss: 25543.5321680951
Epoch 52 recon loss: 25240.4832687081
Epoch 53 recon loss: 26574.060642807
Epoch 54 recon loss: 25860.0338992826
Epoch 55 recon loss: 25268.4940495423
Epoch 56 recon loss: 24380.3986616098
Epoch 57 recon loss: 25582.086115131
Epoch 58 recon loss: 25364.0914148305
Epoch 59 recon loss: 25848.4788632255
Epoch 60 recon loss: 25144.3508499851
Epoch 61 recon loss: 25508.0314975171
Epoch 62 recon loss: 25019.4875702211
Epoch 63 recon loss: 24297.4421108298
Epoch 64 recon loss: 24453.762829458
Epoch 65 recon loss: 24965.7060943338
Epoch 66 recon loss: 24423.8971102507
Epoch 67 recon loss: 25432.3191072593
Epoch 68 recon loss: 24007.2416290379
Epoch 69 recon loss: 24384.1765779694
Epoch 70 recon loss: 24844.4079016261
Epoch 71 recon loss: 24102.2326937975
Epoch 72 recon loss: 24261.3769829151
Epoch 73 recon loss: 24302.4917423163
Epoch 74 recon loss: 24663.8546164565
Epoch 75 recon loss: 24623.3368449789
Epoch 76 recon loss: 24515.3219450428
Epoch 77 recon loss: 24623.8673951608
Epoch 78 recon loss: 23573.3568938413
Epoch 79 recon loss: 24352.724274201
Latent space type: <class 'numpy.ndarray'>;
GEX encoded shape: torch.Size([69249, 10]);
ATAC encoded shape: torch.Size([69249, 10]);
Latent space shape: (69249, 20);
0.5311229722116652
   celltype_ari  celltype_ami  ...  batch_homogeneity  batch_complete
0      0.131597      0.339901  ...           0.844024        0.888081
[1 rows x 8 columns]
 FutureWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/anndata/_core/anndata.py:1228: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.
... storing 'feature_types' as categorical
 FutureWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/anndata/_core/anndata.py:1228: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.
... storing 'gene_id' as categorical