/h/angelo/single-cell-proj/repo/team_single_cell/experiments/jobs
gpu027
Sun Dec 18 14:06:14 EST 2022
wandb: Starting wandb agent üïµÔ∏è
2022-12-18 14:06:22,318 - wandb.wandb_agent - INFO - Running runs: []
2022-12-18 14:06:22,474 - wandb.wandb_agent - INFO - Agent received command: run
2022-12-18 14:06:22,474 - wandb.wandb_agent - INFO - Agent starting run with config:
	atac_dim: 10000
	atac_weight: 57.99225277768179
	epochs: 40
	gex_dim: 2500
	gex_weight: 21.992894950493262
	init: xavier
	latent_dim: 64
	lr: 0.001
	model: [[1000, 800, 600, 400, 200], [10, 30, 50, 100, 160], [1200, 900, 600, 400, 150], [15, 40, 60, 100, 180]]
	weight_decay: 0.06429438339988007
2022-12-18 14:06:22,479 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python gex_atac_sweep.py --atac_dim=10000 --atac_weight=57.99225277768179 --epochs=40 --gex_dim=2500 --gex_weight=21.992894950493262 --init=xavier --latent_dim=64 --lr=0.001 "--model=[[1000, 800, 600, 400, 200], [10, 30, 50, 100, 160], [1200, 900, 600, 400, 150], [15, 40, 60, 100, 180]]" --weight_decay=0.06429438339988007
wandb: Currently logged in as: ange1o5 (team-single-cell). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
2022-12-18 14:06:27,492 - wandb.wandb_agent - INFO - Running runs: ['bkrblffz']
wandb: Tracking run with wandb version 0.13.7
wandb: Run data is saved locally in /ssd003/home/angelo/single-cell-proj/repo/team_single_cell/experiments/scripts/wandb/run-20221218_140626-bkrblffz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-167
wandb: ‚≠êÔ∏è View project at https://wandb.ai/team-single-cell/gex_atac_sweep
wandb: üßπ View sweep at https://wandb.ai/team-single-cell/gex_atac_sweep/sweeps/j1snhit4
wandb: üöÄ View run at https://wandb.ai/team-single-cell/gex_atac_sweep/runs/bkrblffz
 UserWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:64: `flavor='seurat_v3'` expects raw count data, but non-integers were found.
Trying to set attribute `._uns` of view, copying.
Trying to set attribute `.var` of view, copying.
Reading dataset...
Feature selecting GEX...
Feature selecting ATAC...

New GEX dim: 2500;
New ATAC dim: 10002;
AnnData dataset's shape: (69249, 12502)

Initializing dataset and dataloader...
The order of labels: ['s1d1', 's1d1', 's1d1', 's1d1', 's1d1', ..., 's4d9', 's4d9', 's4d9', 's4d9', 's4d9']
Length: 69249
Categories (13, object): ['s1d1', 's1d2', 's1d3', 's2d1', ..., 's3d10', 's4d1', 's4d8', 's4d9']
The device: cuda;

The model: DeepGexAtacMultiModalAutoencoder(
  (gex_encoder): Sequential(
    (0): Linear(in_features=2500, out_features=1000, bias=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1000, out_features=800, bias=True)
    (5): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=800, out_features=600, bias=True)
    (8): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=600, out_features=400, bias=True)
    (12): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Linear(in_features=400, out_features=200, bias=True)
    (15): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU()
    (17): Dropout(p=0.1, inplace=False)
    (18): Linear(in_features=200, out_features=32, bias=True)
    (19): ReLU()
  )
  (atac_encoder): Sequential(
    (0): Linear(in_features=10002, out_features=1200, bias=True)
    (1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1200, out_features=900, bias=True)
    (5): BatchNorm1d(900, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=900, out_features=600, bias=True)
    (8): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=600, out_features=400, bias=True)
    (12): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Linear(in_features=400, out_features=150, bias=True)
    (15): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU()
    (17): Dropout(p=0.1, inplace=False)
    (18): Linear(in_features=150, out_features=32, bias=True)
    (19): ReLU()
  )
  (gex_decoder): Sequential(
    (0): Linear(in_features=64, out_features=10, bias=True)
    (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=10, out_features=30, bias=True)
    (5): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=30, out_features=50, bias=True)
    (8): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=50, out_features=100, bias=True)
    (12): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Linear(in_features=100, out_features=160, bias=True)
    (15): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU()
    (17): Dropout(p=0.1, inplace=False)
    (18): Linear(in_features=160, out_features=2500, bias=True)
    (19): ReLU()
  )
  (atac_decoder): Sequential(
    (0): Linear(in_features=64, out_features=15, bias=True)
    (1): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=15, out_features=40, bias=True)
    (5): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=40, out_features=60, bias=True)
    (8): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=60, out_features=100, bias=True)
    (12): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Linear(in_features=100, out_features=180, bias=True)
    (15): BatchNorm1d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU()
    (17): Dropout(p=0.1, inplace=False)
    (18): Linear(in_features=180, out_features=10002, bias=True)
    (19): Sigmoid()
  )
);
The dataset: <datasets.anndatadataset.AnnDataDataset object at 0x7fc3f8481ad0>;
The optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.06429438339988007
);

Traceback (most recent call last):
  File "gex_atac_sweep.py", line 58, in <module>
    gex_atac_trainer.train(epochs=epochs, gex_loss_w=gex_weight, atac_loss_w=atac_weight, wandb_log=True)
  File "../../train.py", line 87, in train
    outs = self.autoencoder.forward(inputs)
  File "../../models/multimodal_autoencoder.py", line 150, in forward
    gex_Z = self.gex_encode(gex_X)
  File "../../models/multimodal_autoencoder.py", line 130, in gex_encode
    gex_Z = self.gex_encoder(gex_X)
  File "/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 81, in forward
    exponential_average_factor, self.eps)
  File "/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/torch/nn/functional.py", line 1670, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED
2022-12-18 14:20:15,865 - wandb.wandb_agent - INFO - Cleaning up finished run: bkrblffz
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: \ 0.024 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: Synced peachy-sweep-167: https://wandb.ai/team-single-cell/gex_atac_sweep/runs/bkrblffz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20221218_140626-bkrblffz/logs
2022-12-18 14:20:19,738 - wandb.wandb_agent - INFO - Agent received command: run
2022-12-18 14:20:19,738 - wandb.wandb_agent - INFO - Agent starting run with config:
	atac_dim: 5000
	atac_weight: 79.2555024836684
	epochs: 40
	gex_dim: 1000
	gex_weight: 74.61312779487416
	init: he
	latent_dim: 20
	lr: 0.001
	model: [[1000, 800, 600, 400, 200], [10, 30, 50, 100, 160], [1200, 900, 600, 400, 150], [15, 40, 60, 100, 180]]
	weight_decay: 0.08368146288996685
2022-12-18 14:20:19,744 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python gex_atac_sweep.py --atac_dim=5000 --atac_weight=79.2555024836684 --epochs=40 --gex_dim=1000 --gex_weight=74.61312779487416 --init=he --latent_dim=20 --lr=0.001 "--model=[[1000, 800, 600, 400, 200], [10, 30, 50, 100, 160], [1200, 900, 600, 400, 150], [15, 40, 60, 100, 180]]" --weight_decay=0.08368146288996685
2022-12-18 14:20:24,775 - wandb.wandb_agent - INFO - Running runs: ['a63pfdyi']
wandb: Currently logged in as: ange1o5 (team-single-cell). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.7
wandb: Run data is saved locally in /ssd003/home/angelo/single-cell-proj/repo/team_single_cell/experiments/scripts/wandb/run-20221218_142025-a63pfdyi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-400
wandb: ‚≠êÔ∏è View project at https://wandb.ai/team-single-cell/gex_atac_sweep
wandb: üßπ View sweep at https://wandb.ai/team-single-cell/gex_atac_sweep/sweeps/j1snhit4
wandb: üöÄ View run at https://wandb.ai/team-single-cell/gex_atac_sweep/runs/a63pfdyi
 UserWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:64: `flavor='seurat_v3'` expects raw count data, but non-integers were found.
Trying to set attribute `._uns` of view, copying.
Trying to set attribute `.var` of view, copying.
Reading dataset...
Feature selecting GEX...
Feature selecting ATAC...

New GEX dim: 1000;
New ATAC dim: 5001;
AnnData dataset's shape: (69249, 6001)

Initializing dataset and dataloader...
The order of labels: ['s1d1', 's1d1', 's1d1', 's1d1', 's1d1', ..., 's4d9', 's4d9', 's4d9', 's4d9', 's4d9']
Length: 69249
Categories (13, object): ['s1d1', 's1d2', 's1d3', 's2d1', ..., 's3d10', 's4d1', 's4d8', 's4d9']
The device: cuda;

The model: DeepGexAtacMultiModalAutoencoder(
  (gex_encoder): Sequential(
    (0): Linear(in_features=1000, out_features=1000, bias=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1000, out_features=800, bias=True)
    (5): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=800, out_features=600, bias=True)
    (8): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=600, out_features=400, bias=True)
    (12): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Linear(in_features=400, out_features=200, bias=True)
    (15): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU()
    (17): Dropout(p=0.1, inplace=False)
    (18): Linear(in_features=200, out_features=10, bias=True)
    (19): ReLU()
  )
  (atac_encoder): Sequential(
    (0): Linear(in_features=5001, out_features=1200, bias=True)
    (1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1200, out_features=900, bias=True)
    (5): BatchNorm1d(900, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=900, out_features=600, bias=True)
    (8): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=600, out_features=400, bias=True)
    (12): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Linear(in_features=400, out_features=150, bias=True)
    (15): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU()
    (17): Dropout(p=0.1, inplace=False)
    (18): Linear(in_features=150, out_features=10, bias=True)
    (19): ReLU()
  )
  (gex_decoder): Sequential(
    (0): Linear(in_features=20, out_features=10, bias=True)
    (1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=10, out_features=30, bias=True)
    (5): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=30, out_features=50, bias=True)
    (8): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=50, out_features=100, bias=True)
    (12): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Linear(in_features=100, out_features=160, bias=True)
    (15): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU()
    (17): Dropout(p=0.1, inplace=False)
    (18): Linear(in_features=160, out_features=1000, bias=True)
    (19): ReLU()
  )
  (atac_decoder): Sequential(
    (0): Linear(in_features=20, out_features=15, bias=True)
    (1): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=15, out_features=40, bias=True)
    (5): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=40, out_features=60, bias=True)
    (8): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU()
    (10): Dropout(p=0.1, inplace=False)
    (11): Linear(in_features=60, out_features=100, bias=True)
    (12): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU()
    (14): Linear(in_features=100, out_features=180, bias=True)
    (15): BatchNorm1d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU()
    (17): Dropout(p=0.1, inplace=False)
    (18): Linear(in_features=180, out_features=5001, bias=True)
    (19): Sigmoid()
  )
);
The dataset: <datasets.anndatadataset.AnnDataDataset object at 0x7f3a853f5f90>;
The optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.08368146288996685
);

wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: Synced fearless-sweep-400: https://wandb.ai/team-single-cell/gex_atac_sweep/runs/a63pfdyi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20221218_142025-a63pfdyi/logs
Traceback (most recent call last):
  File "gex_atac_sweep.py", line 58, in <module>
    gex_atac_trainer.train(epochs=epochs, gex_loss_w=gex_weight, atac_loss_w=atac_weight, wandb_log=True)
  File "../../train.py", line 87, in train
    outs = self.autoencoder.forward(inputs)
  File "../../models/multimodal_autoencoder.py", line 150, in forward
    gex_Z = self.gex_encode(gex_X)
  File "../../models/multimodal_autoencoder.py", line 130, in gex_encode
    gex_Z = self.gex_encoder(gex_X)
  File "/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 81, in forward
    exponential_average_factor, self.eps)
  File "/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/torch/nn/functional.py", line 1670, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED
2022-12-18 14:31:54,240 - wandb.wandb_agent - INFO - Cleaning up finished run: a63pfdyi
2022-12-18 14:31:54,431 - wandb.wandb_agent - INFO - Agent received command: run
2022-12-18 14:31:54,431 - wandb.wandb_agent - INFO - Agent starting run with config:
	atac_dim: 2500
	atac_weight: 96.21651575103496
	epochs: 40
	gex_dim: 5000
	gex_weight: 31.377563654319935
	init: he
	latent_dim: 128
	lr: 0.001
	model: [[1200, 400, 100], [50, 100, 200], [1600, 600, 120], [60, 100, 150]]
	weight_decay: 0.009390868997977551
2022-12-18 14:31:54,435 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python gex_atac_sweep.py --atac_dim=2500 --atac_weight=96.21651575103496 --epochs=40 --gex_dim=5000 --gex_weight=31.377563654319935 --init=he --latent_dim=128 --lr=0.001 "--model=[[1200, 400, 100], [50, 100, 200], [1600, 600, 120], [60, 100, 150]]" --weight_decay=0.009390868997977551
2022-12-18 14:31:59,448 - wandb.wandb_agent - INFO - Running runs: ['o7ai8yeh']
wandb: Currently logged in as: ange1o5 (team-single-cell). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.7
wandb: Run data is saved locally in /ssd003/home/angelo/single-cell-proj/repo/team_single_cell/experiments/scripts/wandb/run-20221218_143159-o7ai8yeh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-534
wandb: ‚≠êÔ∏è View project at https://wandb.ai/team-single-cell/gex_atac_sweep
wandb: üßπ View sweep at https://wandb.ai/team-single-cell/gex_atac_sweep/sweeps/j1snhit4
wandb: üöÄ View run at https://wandb.ai/team-single-cell/gex_atac_sweep/runs/o7ai8yeh
slurmstepd: error: *** JOB 8874597 ON gpu027 CANCELLED AT 2022-12-18T14:32:15 ***
