/h/angelo/single-cell-proj/repo/team_single_cell/experiments/jobs
gpu106
Sun Dec 18 14:05:21 EST 2022
wandb: Starting wandb agent üïµÔ∏è
2022-12-18 14:05:31,326 - wandb.wandb_agent - INFO - Running runs: []
2022-12-18 14:05:31,528 - wandb.wandb_agent - INFO - Agent received command: run
2022-12-18 14:05:31,528 - wandb.wandb_agent - INFO - Agent starting run with config:
	atac_dim: 2500
	atac_weight: 51.989832583135
	epochs: 60
	gex_dim: 2500
	gex_weight: 37.61562221000536
	init: xavier
	latent_dim: 10
	lr: 1e-05
	model: [[1000, 200], [50, 100], [2000, 400], [100, 300]]
	weight_decay: 0.028839664497215024
2022-12-18 14:05:31,539 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python gex_atac_sweep.py --atac_dim=2500 --atac_weight=51.989832583135 --epochs=60 --gex_dim=2500 --gex_weight=37.61562221000536 --init=xavier --latent_dim=10 --lr=1e-05 "--model=[[1000, 200], [50, 100], [2000, 400], [100, 300]]" --weight_decay=0.028839664497215024
2022-12-18 14:05:36,552 - wandb.wandb_agent - INFO - Running runs: ['3ok9a64d']
wandb: Currently logged in as: ange1o5 (team-single-cell). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.7
wandb: Run data is saved locally in /ssd003/home/angelo/single-cell-proj/repo/team_single_cell/experiments/scripts/wandb/run-20221218_140539-3ok9a64d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-117
wandb: ‚≠êÔ∏è View project at https://wandb.ai/team-single-cell/gex_atac_sweep
wandb: üßπ View sweep at https://wandb.ai/team-single-cell/gex_atac_sweep/sweeps/j1snhit4
wandb: üöÄ View run at https://wandb.ai/team-single-cell/gex_atac_sweep/runs/3ok9a64d
 UserWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:64: `flavor='seurat_v3'` expects raw count data, but non-integers were found.
Trying to set attribute `._uns` of view, copying.
Trying to set attribute `.var` of view, copying.
2022-12-18 14:24:12.272948: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
 FutureWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/anndata/_core/anndata.py:1228: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.
... storing 'feature_types' as categorical
 FutureWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/anndata/_core/anndata.py:1228: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.
... storing 'gene_id' as categorical
Reading dataset...
Feature selecting GEX...
Feature selecting ATAC...

New GEX dim: 2500;
New ATAC dim: 2501;
AnnData dataset's shape: (69249, 5001)

Initializing dataset and dataloader...
The order of labels: ['s1d1', 's1d1', 's1d1', 's1d1', 's1d1', ..., 's4d9', 's4d9', 's4d9', 's4d9', 's4d9']
Length: 69249
Categories (13, object): ['s1d1', 's1d2', 's1d3', 's2d1', ..., 's3d10', 's4d1', 's4d8', 's4d9']
The device: cuda;

The model: DeepGexAtacMultiModalAutoencoder(
  (gex_encoder): Sequential(
    (0): Linear(in_features=2500, out_features=1000, bias=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1000, out_features=200, bias=True)
    (5): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=200, out_features=5, bias=True)
    (8): ReLU()
  )
  (atac_encoder): Sequential(
    (0): Linear(in_features=2501, out_features=2000, bias=True)
    (1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=2000, out_features=400, bias=True)
    (5): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=400, out_features=5, bias=True)
    (8): ReLU()
  )
  (gex_decoder): Sequential(
    (0): Linear(in_features=10, out_features=50, bias=True)
    (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=50, out_features=100, bias=True)
    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=100, out_features=2500, bias=True)
    (8): ReLU()
  )
  (atac_decoder): Sequential(
    (0): Linear(in_features=10, out_features=100, bias=True)
    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=100, out_features=300, bias=True)
    (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=300, out_features=2501, bias=True)
    (8): Sigmoid()
  )
);
The dataset: <datasets.anndatadataset.AnnDataDataset object at 0x7f1694384890>;
The optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0.028839664497215024
);

Epoch 0 recon loss: 6221.9129146085
Epoch 1 recon loss: 6282.6696280881
Epoch 2 recon loss: 6313.7308441948
Epoch 3 recon loss: 6298.1048143464
Epoch 4 recon loss: 6091.1247855413
Epoch 5 recon loss: 6185.5292457289
Epoch 6 recon loss: 6001.8662186338
Epoch 7 recon loss: 6058.8639382505
Epoch 8 recon loss: 6331.2013080402
Epoch 9 recon loss: 6264.2854376149
Epoch 10 recon loss: 6132.1402026807
Epoch 11 recon loss: 6271.9924674261
Epoch 12 recon loss: 6248.302210207
Epoch 13 recon loss: 6158.6138421006
Epoch 14 recon loss: 5967.0671839603
Epoch 15 recon loss: 6204.9274437274
Epoch 16 recon loss: 6201.0489918954
Epoch 17 recon loss: 6273.1604069313
Epoch 18 recon loss: 6251.7440530304
Epoch 19 recon loss: 6308.8979330604
Epoch 20 recon loss: 6261.0770278543
Epoch 21 recon loss: 6185.4430185878
Epoch 22 recon loss: 6234.7948526216
Epoch 23 recon loss: 6269.0589040248
Epoch 24 recon loss: 6357.8333432069
Epoch 25 recon loss: 6285.8005926622
Epoch 26 recon loss: 6290.6964802595
Epoch 27 recon loss: 6398.7688482716
Epoch 28 recon loss: 6328.1623939701
Epoch 29 recon loss: 6198.3278110801
Epoch 30 recon loss: 5836.3124783255
Epoch 31 recon loss: 6415.8427297415
Epoch 32 recon loss: 6317.2767061679
Epoch 33 recon loss: 6228.7324558974
Epoch 34 recon loss: 6152.7272486783
Epoch 35 recon loss: 6260.0123731847
Epoch 36 recon loss: 6372.9871470378
Epoch 37 recon loss: 6233.447108298
Epoch 38 recon loss: 5990.9097531748
Epoch 39 recon loss: 6251.0984257071
Epoch 40 recon loss: 6172.0630801862
Epoch 41 recon loss: 6066.9141238122
Epoch 42 recon loss: 6141.3783004258
Epoch 43 recon loss: 5881.7140247112
Epoch 44 recon loss: 6296.8716886591
Epoch 45 recon loss: 6200.8428930285
Epoch 46 recon loss: 6134.1621219887
Epoch 47 recon loss: 6327.8209076177
Epoch 48 recon loss: 6018.8242162272
Epoch 49 recon loss: 5841.9826554878
Epoch 50 recon loss: 6310.2767676072
Epoch 51 recon loss: 6279.4120215585
Epoch 52 recon loss: 6258.7878839236
Epoch 53 recon loss: 6112.7647864051
Epoch 54 recon loss: 6207.7702609523
Epoch 55 recon loss: 6326.8639933904
Epoch 56 recon loss: 6285.6739338746
Epoch 57 recon loss: 6139.071165833
Epoch 58 recon loss: 5745.5313338574
Epoch 59 recon loss: 6081.8757847887

Latent space type: <class 'numpy.ndarray'>;
GEX encoded shape: torch.Size([69249, 5]);
ATAC encoded shape: torch.Size([69249, 5]);
Latent space shape: (69249, 10);

0.44672153890971394
   celltype_ari  celltype_ami  ...  batch_homogeneity  batch_complete
0      0.045592       0.18131  ...           0.840453        0.888522

[1 rows x 8 columns]
2022-12-18 14:27:30,731 - wandb.wandb_agent - INFO - Cleaning up finished run: 3ok9a64d
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  recon loss ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñà‚ñá‚ñÅ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÑ
wandb: total_score ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  recon loss 6081.87578
wandb: total_score 0.44672
wandb: 
wandb: Synced summer-sweep-117: https://wandb.ai/team-single-cell/gex_atac_sweep/runs/3ok9a64d
wandb: Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20221218_140539-3ok9a64d/logs
2022-12-18 14:27:36,327 - wandb.wandb_agent - INFO - Agent received command: run
2022-12-18 14:27:36,328 - wandb.wandb_agent - INFO - Agent starting run with config:
	atac_dim: 10000
	atac_weight: 4.22994500990694
	epochs: 60
	gex_dim: 5000
	gex_weight: 94.20189845314296
	init: xavier
	latent_dim: 64
	lr: 0.01
	model: [[1600, 800, 400, 100], [40, 60, 100, 150], [1800, 800, 400, 100], [40, 60, 120, 200]]
	weight_decay: 0.0646101159311958
2022-12-18 14:27:36,363 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python gex_atac_sweep.py --atac_dim=10000 --atac_weight=4.22994500990694 --epochs=60 --gex_dim=5000 --gex_weight=94.20189845314296 --init=xavier --latent_dim=64 --lr=0.01 "--model=[[1600, 800, 400, 100], [40, 60, 100, 150], [1800, 800, 400, 100], [40, 60, 120, 200]]" --weight_decay=0.0646101159311958
2022-12-18 14:27:41,392 - wandb.wandb_agent - INFO - Running runs: ['ar788flo']
wandb: Currently logged in as: ange1o5 (team-single-cell). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.7
wandb: Run data is saved locally in /ssd003/home/angelo/single-cell-proj/repo/team_single_cell/experiments/scripts/wandb/run-20221218_142742-ar788flo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-456
wandb: ‚≠êÔ∏è View project at https://wandb.ai/team-single-cell/gex_atac_sweep
wandb: üßπ View sweep at https://wandb.ai/team-single-cell/gex_atac_sweep/sweeps/j1snhit4
wandb: üöÄ View run at https://wandb.ai/team-single-cell/gex_atac_sweep/runs/ar788flo
 UserWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:64: `flavor='seurat_v3'` expects raw count data, but non-integers were found.
Trying to set attribute `._uns` of view, copying.
Trying to set attribute `.var` of view, copying.
slurmstepd: error: *** JOB 8874548 ON gpu106 CANCELLED AT 2022-12-18T14:32:15 ***
