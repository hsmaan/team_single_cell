/h/angelo/single-cell-proj/repo/team_single_cell/experiments/jobs
gpu180.cluster.local
Sun Dec 18 14:07:38 EST 2022
wandb: Starting wandb agent üïµÔ∏è
2022-12-18 14:07:48,792 - wandb.wandb_agent - INFO - Running runs: []
2022-12-18 14:07:48,990 - wandb.wandb_agent - INFO - Agent received command: run
2022-12-18 14:07:48,990 - wandb.wandb_agent - INFO - Agent starting run with config:
	atac_dim: 5000
	atac_weight: 58.73454695965625
	epochs: 60
	gex_dim: 1000
	gex_weight: 63.47352663465586
	init: he
	latent_dim: 64
	lr: 0.1
	model: [[1000, 200], [50, 100], [2000, 400], [100, 300]]
	weight_decay: 0.03811251962386114
2022-12-18 14:07:48,998 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python gex_atac_sweep.py --atac_dim=5000 --atac_weight=58.73454695965625 --epochs=60 --gex_dim=1000 --gex_weight=63.47352663465586 --init=he --latent_dim=64 --lr=0.1 "--model=[[1000, 200], [50, 100], [2000, 400], [100, 300]]" --weight_decay=0.03811251962386114
2022-12-18 14:07:54,008 - wandb.wandb_agent - INFO - Running runs: ['6688m7kc']
wandb: Currently logged in as: ange1o5 (team-single-cell). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.7
wandb: Run data is saved locally in /ssd003/home/angelo/single-cell-proj/repo/team_single_cell/experiments/scripts/wandb/run-20221218_140756-6688m7kc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-257
wandb: ‚≠êÔ∏è View project at https://wandb.ai/team-single-cell/gex_atac_sweep
wandb: üßπ View sweep at https://wandb.ai/team-single-cell/gex_atac_sweep/sweeps/j1snhit4
wandb: üöÄ View run at https://wandb.ai/team-single-cell/gex_atac_sweep/runs/6688m7kc
 UserWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:64: `flavor='seurat_v3'` expects raw count data, but non-integers were found.
Trying to set attribute `._uns` of view, copying.
Trying to set attribute `.var` of view, copying.
2022-12-18 14:22:33.354255: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-18 14:22:33.467607: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
 FutureWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/anndata/_core/anndata.py:1228: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.
... storing 'feature_types' as categorical
 FutureWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/anndata/_core/anndata.py:1228: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.
... storing 'gene_id' as categorical
Reading dataset...
Feature selecting GEX...
Feature selecting ATAC...

New GEX dim: 1000;
New ATAC dim: 5001;
AnnData dataset's shape: (69249, 6001)

Initializing dataset and dataloader...
The order of labels: ['s1d1', 's1d1', 's1d1', 's1d1', 's1d1', ..., 's4d9', 's4d9', 's4d9', 's4d9', 's4d9']
Length: 69249
Categories (13, object): ['s1d1', 's1d2', 's1d3', 's2d1', ..., 's3d10', 's4d1', 's4d8', 's4d9']
The device: cuda;

The model: DeepGexAtacMultiModalAutoencoder(
  (gex_encoder): Sequential(
    (0): Linear(in_features=1000, out_features=1000, bias=True)
    (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1000, out_features=200, bias=True)
    (5): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=200, out_features=32, bias=True)
    (8): ReLU()
  )
  (atac_encoder): Sequential(
    (0): Linear(in_features=5001, out_features=2000, bias=True)
    (1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=2000, out_features=400, bias=True)
    (5): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=400, out_features=32, bias=True)
    (8): ReLU()
  )
  (gex_decoder): Sequential(
    (0): Linear(in_features=64, out_features=50, bias=True)
    (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=50, out_features=100, bias=True)
    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=100, out_features=1000, bias=True)
    (8): ReLU()
  )
  (atac_decoder): Sequential(
    (0): Linear(in_features=64, out_features=100, bias=True)
    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=100, out_features=300, bias=True)
    (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Linear(in_features=300, out_features=5001, bias=True)
    (8): Sigmoid()
  )
);
The dataset: <datasets.anndatadataset.AnnDataDataset object at 0x7f74e4035e90>;
The optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.1
    weight_decay: 0.03811251962386114
);

Epoch 0 recon loss: 17849.7600011456
Epoch 1 recon loss: 8505.3607864777
Epoch 2 recon loss: 6619.1221740187
Epoch 3 recon loss: 5485.4969737228
Epoch 4 recon loss: 5891.4638944762
Epoch 5 recon loss: 4314.7154980692
Epoch 6 recon loss: 3441.9680024963
Epoch 7 recon loss: 3098.3561864136
Epoch 8 recon loss: 3340.9504024643
Epoch 9 recon loss: 3228.837326165
Epoch 10 recon loss: 3079.0355169817
Epoch 11 recon loss: 3429.8761403445
Epoch 12 recon loss: 3335.1226499593
Epoch 13 recon loss: 2395.0444190937
Epoch 14 recon loss: 2107.8827572643
Epoch 15 recon loss: 2456.1971940092
Epoch 16 recon loss: 4015.8515494888
Epoch 17 recon loss: 10405.0107959497
Epoch 18 recon loss: 3944.792697151
Epoch 19 recon loss: 2296.0649395781
Epoch 20 recon loss: 2195.2185776583
Epoch 21 recon loss: 2095.5678335918
Epoch 22 recon loss: 2137.632889877
Epoch 23 recon loss: 2565.1761083396
Epoch 24 recon loss: 1820.9587332432
Epoch 25 recon loss: 2720.2519464061
Epoch 26 recon loss: 1869.4404263658
Epoch 27 recon loss: 1937.8650213192
Epoch 28 recon loss: 3054.5539489414
Epoch 29 recon loss: 2520.8082884688
Epoch 30 recon loss: 2053.9873247533
Epoch 31 recon loss: 4786.3346237338
Epoch 32 recon loss: 2359.9965295845
Epoch 33 recon loss: 1834.1382918692
Epoch 34 recon loss: 2546.0610958963
Epoch 35 recon loss: 1623.0868887575
Epoch 36 recon loss: 2224.7994002784
Epoch 37 recon loss: 1846.3946819255
Epoch 38 recon loss: 2690.9347960657
Epoch 39 recon loss: 2888.4124010516
Epoch 40 recon loss: 2669.4835954881
Epoch 41 recon loss: 2207.5218083252
Epoch 42 recon loss: 2853.3515484709
Epoch 43 recon loss: 1704.0614129213
Epoch 44 recon loss: 1605.8747906098
Epoch 45 recon loss: 1815.3871503533
Epoch 46 recon loss: 1870.1854834251
Epoch 47 recon loss: 1704.1934506655
Epoch 48 recon loss: 1869.7490651209
Epoch 49 recon loss: 2425.1745611071
Epoch 50 recon loss: 2443.0742358559
Epoch 51 recon loss: 1801.3737027004
Epoch 52 recon loss: 1905.5588233391
Epoch 53 recon loss: 1469.2416519811
Epoch 54 recon loss: 1489.4352948149
Epoch 55 recon loss: 2063.674893955
Epoch 56 recon loss: 1771.9415070505
Epoch 57 recon loss: 2031.561553579
Epoch 58 recon loss: 1685.0086971062
Epoch 59 recon loss: 2067.3111298621

Latent space type: <class 'numpy.ndarray'>;
GEX encoded shape: torch.Size([69249, 32]);
ATAC encoded shape: torch.Size([69249, 32]);
Latent space shape: (69249, 64);

0.4951252953163214
   celltype_ari  celltype_ami  ...  batch_homogeneity  batch_complete
0      0.047938      0.276394  ...           0.822389        0.899768

[1 rows x 8 columns]
2022-12-18 14:26:31,825 - wandb.wandb_agent - INFO - Cleaning up finished run: 6688m7kc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:  recon loss ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: total_score ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  recon loss 2067.31113
wandb: total_score 0.49513
wandb: 
wandb: Synced still-sweep-257: https://wandb.ai/team-single-cell/gex_atac_sweep/runs/6688m7kc
wandb: Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20221218_140756-6688m7kc/logs
2022-12-18 14:26:37,247 - wandb.wandb_agent - INFO - Agent received command: run
2022-12-18 14:26:37,247 - wandb.wandb_agent - INFO - Agent starting run with config:
	atac_dim: 5000
	atac_weight: 55.18052519623458
	epochs: 40
	gex_dim: 5000
	gex_weight: 11.973082350003317
	init: xavier
	latent_dim: 20
	lr: 1e-05
	model: [[1600, 800, 400, 100], [40, 60, 100, 150], [1800, 800, 400, 100], [40, 60, 120, 200]]
	weight_decay: 0.05960644507169081
2022-12-18 14:26:37,310 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python gex_atac_sweep.py --atac_dim=5000 --atac_weight=55.18052519623458 --epochs=40 --gex_dim=5000 --gex_weight=11.973082350003317 --init=xavier --latent_dim=20 --lr=1e-05 "--model=[[1600, 800, 400, 100], [40, 60, 100, 150], [1800, 800, 400, 100], [40, 60, 120, 200]]" --weight_decay=0.05960644507169081
2022-12-18 14:26:42,363 - wandb.wandb_agent - INFO - Running runs: ['sdvmxsch']
wandb: Currently logged in as: ange1o5 (team-single-cell). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: WARNING Ignored wandb.init() arg entity when running a sweep.
wandb: Tracking run with wandb version 0.13.7
wandb: Run data is saved locally in /ssd003/home/angelo/single-cell-proj/repo/team_single_cell/experiments/scripts/wandb/run-20221218_142642-sdvmxsch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-444
wandb: ‚≠êÔ∏è View project at https://wandb.ai/team-single-cell/gex_atac_sweep
wandb: üßπ View sweep at https://wandb.ai/team-single-cell/gex_atac_sweep/sweeps/j1snhit4
wandb: üöÄ View run at https://wandb.ai/team-single-cell/gex_atac_sweep/runs/sdvmxsch
 UserWarning:/h/angelo/miniconda3/envs/single_cell_env/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py:64: `flavor='seurat_v3'` expects raw count data, but non-integers were found.
Trying to set attribute `._uns` of view, copying.
Trying to set attribute `.var` of view, copying.
slurmstepd: error: *** JOB 8874688 ON gpu180 CANCELLED AT 2022-12-18T14:32:15 ***
